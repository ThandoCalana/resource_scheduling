ğŸ“˜ Explanation of My Slipstream SQL + LLM Chatbot Assistant

This project is a conversational assistant that connects directly to SQL Server, reads meeting and workload data, and then uses a Large Language Model (LLM) â€” in this case the Llama model running through Ollama â€” to turn raw database rows into natural, friendly conversational answers.

My goal was to build a system where someone can ask questions like:

â€œWhat meetings does Andrew have on Wednesday?â€

â€œIs he free from 9 to 10 tomorrow?â€

â€œWho is the busiest this week?â€

â€œCompare Robin's meetings to Palesa.â€

â€œWhat about him?â€ (Follow-up questions)

â€¦and the assistant will:

Understand the intent behind the question

Extract names, dates, times, workloads, and context

Pull the right data from SQL Server

Format that data into readable context

Give it to the LLM, which then

Responds in natural language â€” like a colleague, not a database

This document explains how the entire script works, from start to finish.

ğŸ”§ 1. System Setup & Configuration

At the top of the file, I import Python libraries I need â€” things like:

OS and environment handling

Regex for text analysis

Pandas for data processing

SQLAlchemy for database connections

Ollama for LLM communication

The .env loader so I can store SQL credentials securely

I load the settings that control the system:

SQL_SERVER
SQL_DATABASE
SQL_DRIVER

These tell my program where SQL Server lives, what table the meeting data is in, and which AI model it should use when generating natural responses.

ğŸ›¢ï¸ 2. Connecting to SQL Server

I wrote a function called build_sql_engine().

What this does:

It takes my SQL settings

Builds a proper connection string

Uses Windows Authentication (â€œTrusted Connectionâ€)

Creates a SQLAlchemy engine

This engine is what allows the assistant to send real SQL queries to the database.

If the user forgets to provide the server or database name, it stops immediately and explains the error.

ğŸ§  3. Understanding User Intent

Before running any SQL at all, my system tries to understand what the user is asking for.
This is handled by extract_query_intent().

This is one of the most important parts of the entire system.

It does things like:

âœ” Detect â€œchitchatâ€

If someone types â€œhiâ€, â€œhelloâ€, â€œthanksâ€, etc.,
I detect that itâ€™s a greeting, not a data question.

âœ” Detect follow-up questions

My system can tell when a user is referring to previous context:

â€œWhat about him?â€

â€œAnd on that day?â€

â€œWhat about Tuesday?â€

It detects these using pronouns and cues like â€œwhat aboutâ€.

âœ” Detect the type of query

I analyze whether the user is asking for:

Availability

Busy periods / workload

Who is busiest

Future meetings

Comparisons

General meeting lookup

Count of meetings

High-load analysis (â€œover 70% busyâ€)

âœ” Extract filters

Based on the question, I extract:

Names

Dates

Weekdays

Date ranges (this week, next month, etc.)

Time ranges

Workload thresholds

These filters later get turned into SQL conditions.

ğŸ‘¤ 4. Extracting Names

The extract_name() function tries to figure out who the user is talking about.

It is smart enough to:

Detect proper names

Ignore month names, weekdays, and filler words

Detect references to previous people (â€œheâ€, â€œherâ€, â€œthemâ€)

Avoid false positives

If it canâ€™t find a name, the query still works â€” just without a name filter.

ğŸ“… 5. Extracting Dates, Weeks, and Times

The extract_date_info() function interprets phrases like:

â€œ2025-11-10â€

â€œ12/02/2025â€

â€œtomorrowâ€

â€œnext Fridayâ€

â€œthis weekâ€

â€œnext monthâ€

It even converts local natural language into ISO dates that SQL Server understands.

This allows the user to speak naturally without typing exact database formats.

ğŸ“Š 6. Detecting Workload / High Load Queries

If the user says things like:

â€œover 80%â€

â€œvery busyâ€

â€œhigh loadâ€

â€¦I treat it as a workload-based query and extract the threshold.

ğŸ§© 7. Building SQL Queries Dynamically

The function build_query() takes the extracted filters and turns them into a real SQL query.

Examples:

If name = Andrew â†’ add â€œWHERE first_name = Andrewâ€

If date = 2025-11-10 â†’ add â€œCAST(date AS DATE) = â€¦â€

If range = this week â†’ automatically calculate Mondayâ€“Sunday

This gives me flexible SQL based entirely on what the user asked.

ğŸŸ¦ 8. Executing SQL Queries

execute_query() runs the SQL against SQL Server using the engine from earlier.

It prints debug information like:

SQL command

Parameters

Number of returned rows

This helps with troubleshooting.

ğŸ§¾ 9. Formatting the Data for the LLM

The LLM cannot read DataFrames directly.

So I wrote a function that converts them into bullet-point meeting summaries:

â€¢ Andrew | 2025-11-10 09:00-10:00 | Daily Stand-Up | Load: 70%


This context is then fed into the AI model.

ğŸ’¬ 10. Keeping Short-Term Memory of Conversations

The system stores the latest messages and intents so that the assistant can:

Understand follow-up questions

Remember the previous filters

Use context in multi-turn conversations

This memory is capped (so it doesnâ€™t get too large).

ğŸ§  11. Talking to the LLM (Ollama + Llama)

ask_llama() is where the magic happens.

It gives the Llama model:

A system prompt describing how it should behave

The meeting context pulled from SQL

The recent conversation history

The userâ€™s latest question

The AI then writes a natural conversational answer,
based entirely on the database rows it received.

It never exposes SQL or tables â€” only a human-style explanation.

ğŸ¤– 12. The Main Conversational Assistant Class

The ConversationalAssistant class holds together:

Intent detection

SQL execution

Context formatting

LLM response generation

Conversation memory

Its job is to orchestrate everything.

The key function is:

process_query()

This is the pipeline:

Understand intent

Check if it's chitchat

Check if filters exist

Run SQL if needed

Convert SQL results to readable context

Ask Llama for a natural response

Store conversation memory

Return the assistantâ€™s message

This makes it feel like a smooth interactive system.

ğŸ–¥ï¸ 13. The Interactive Chat Loop

At the bottom, the chat_loop() function creates the final user experience.

When you run the file, it:

Connects to SQL Server

Initializes the assistant

Displays a friendly header

Starts an infinite loop

Lets the user ask natural questions

Passes them to the assistant

Prints the answer

Users can type:

exit â†’ quit

clear â†’ reset conversation memory

It turns the whole script into a local chatbot terminal.